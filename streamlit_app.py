import streamlit as st
import os
import json
import re
from pathlib import Path

# ğŸ”§ ì‚¬ìš©ì ì •ì˜: JSON í´ë” ê²½ë¡œ
DATA_PATH = Path("results")

# ğŸ” ëª¨ë¸ í‚¤ â†’ ì´ë¦„ ë§¤í•‘
MODEL_MAP = {
    "llm_a": "claude_sonnet4",
    "llm_b": "chatgpt4o",
    "llm_c": "gemini_pro"
}

# ğŸ“ í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="AgentAI Viewer", page_icon="ğŸ§ ")

# âœ… ğŸ“ í˜ì´ì§€ ì„ íƒ ì¶”ê°€
st.sidebar.markdown("### ğŸ“ í˜ì´ì§€ ì„ íƒ")
page = st.sidebar.radio("í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”", [
    "ì‘ë‹µ ë¹„êµ ë³´ê¸°",
    "í–¥í›„ í”¼ë“œë°± ë°©í–¥ì„±",
    "ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ"
])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… 1. ì‘ë‹µ ë¹„êµ ë³´ê¸°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if page == "ì‘ë‹µ ë¹„êµ ë³´ê¸°":
    json_files = sorted(DATA_PATH.glob("*.json"))
    query_map = {f.stem: f for f in json_files}

    st.sidebar.title("ğŸ” Query Navigation")
    selected_query = st.sidebar.selectbox("Select Query", list(query_map.keys()))

    with st.sidebar.expander("ğŸ“‹ í‰ê°€ ê¸°ì¤€ ë³´ê¸°"):
        st.markdown("""
**ğŸ§ª í‰ê°€ ê¸°ì¤€ (ê° í•­ëª©ë‹¹ 10ì  ë§Œì )**

| ë²ˆí˜¸ | í•­ëª© | ì„¤ëª… |
|------|------|------|
| 1 | ëª…í™•ì„± ë° ê°€ë…ì„± | ì„¤ëª…ì´ ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ì˜ ì •ë¦¬ë˜ì—ˆëŠ”ê°€? |
| 2 | ì •í™•ì„± ë° ì™„ì „ì„± | ìš”êµ¬ëœ ëª¨ë“  í•­ëª©ì´ ë¹ ì§ì—†ì´ í¬í•¨ë˜ì—ˆëŠ”ê°€? |
| 3 | CNAPS ìŠ¤íƒ€ì¼ ì›Œí¬í”Œë¡œìš° | ë¶„ê¸°(branch), ë³‘í•©(merge) ë“± ì‹œëƒ…ìŠ¤ êµ¬ì¡°ê°€ ë°˜ì˜ë˜ì—ˆëŠ”ê°€? |
| 4 | ì œê³µ ëª¨ë¸ë§Œ ì‚¬ìš© | ë¬¸ì œì—ì„œ ì œì‹œí•œ ëª¨ë¸ë§Œì„ ì‚¬ìš©í–ˆëŠ”ê°€? |
| 5 | í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì„¤ë“ë ¥ | ì„ íƒ ëª¨ë¸ì˜ ê·¼ê±°ì™€ ì„¤ëª…ì´ ì„¤ë“ë ¥ ìˆì—ˆëŠ”ê°€? |
""")

    with open(query_map[selected_query], 'r') as f:
        data = json.load(f)

    query_text = data.get("query_text", "")
    responses = data.get("responses", {})
    votes = data.get("votes", {})
    majority = data.get("majority_vote", "")

    ask_match = re.search(r"A user asks:\n[\"â€œ](.+?)[\"â€]", query_text, re.DOTALL)
    user_ask = ask_match.group(1).strip() if ask_match else "(ì‚¬ìš©ì ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)"

    model_block_match = re.search(r"### Recommended AI Models:\s*\n(.+)", query_text, re.DOTALL)
    models_raw = model_block_match.group(1).strip() if model_block_match else "(ëª¨ë¸ ëª©ë¡ ì—†ìŒ)"
    models_clean = re.findall(r"- \*\*(.*?)\*\*\n\s*Paper: (.*)", models_raw)
    models_md = "\n".join([f"- **{name}**\n  Paper: {link}" for name, link in models_clean]) if models_clean else models_raw

    st.markdown("## ğŸ™‹ ì‚¬ìš©ì ì§ˆë¬¸")
    st.info(f"**\"{user_ask}\"**")

    st.markdown("## ğŸ§  ì¶”ì²œëœ AI ëª¨ë¸ ëª©ë¡")
    st.code(models_md, language="markdown")

    st.markdown("## ğŸ¤– Model Responses")
    for raw_key in ["llm_a", "llm_b", "llm_c"]:
        response = responses.get(raw_key, "(No response found)")
        mapped_name = MODEL_MAP.get(raw_key, raw_key)
        voted_by = [model for model, v in votes.items() if v == raw_key]
        majority_flag = "ğŸŒŸ **Majority Vote**" if raw_key == majority else ""

        with st.expander(f"ğŸ§  {mapped_name}", expanded=True):
            st.markdown(response, unsafe_allow_html=True)
            st.markdown(f"âœ… **Voted by**: {', '.join(voted_by) if voted_by else 'None'}")
            if majority_flag:
                st.markdown(majority_flag)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… 2. í–¥í›„ í”¼ë“œë°± ë°©í–¥ì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "í–¥í›„ í”¼ë“œë°± ë°©í–¥ì„±":
    st.title("ğŸ§­ í–¥í›„ í”¼ë“œë°± ë°©í–¥ì„± ë° ê°œì„  ì „ëµ")
    st.markdown("""
---

### ğŸ” ë¬¸ì œì  ì •ë¦¬

1. **Mermaid ê¸°ë°˜ íë¦„ë„ ìƒì„± ì˜¤ë¥˜**
2. **Low-level ì¤‘ì‹¬ ì‘ë‹µ ê²½í–¥**
3. **RAG ì¶”ì²œ ëª¨ë¸ì˜ ê³¼ì‚¬ìš©**

---

### âœ… í•´ê²° ë°©ì•ˆ

- ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ LLM ì‘ë‹µ ì¬ìƒì„±
- êµ¬ì¡° ê°œì„  ë° ë³µì¡ë„ ì™„í™”
- ë¶ˆí•„ìš”í•œ ëª¨ë¸ ì œê±° ë° ê°„ê²°í•œ CNAPS êµ¬ì„± ìœ ë„

---
""")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… 3. ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ (ì¸ë±ìŠ¤ ê¸°ë°˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ":
    st.title("ğŸ“Š LLM ì˜ˆì¸¡ ê²°ê³¼ vs ì •ë‹µ ë¹„êµ")

    pred_file_path = "results/generated_predictions_extracted.json"

    if os.path.exists(pred_file_path):
        with open(pred_file_path, "r", encoding="utf-8") as f:
            prediction_data = json.load(f)

        st.sidebar.markdown("### ğŸ”¢ í•­ëª© ì„ íƒ")
        example_idx = st.sidebar.number_input("ì¸ë±ìŠ¤ ì„ íƒ", min_value=0, max_value=len(prediction_data)-1, value=0, step=1)
        example = prediction_data[example_idx]

        st.markdown("## ğŸ™‹ Prompt (User Input)")
        st.code(example["prompt"], language="markdown")

        st.markdown("## ğŸ¤– Predict (LLM Output)")
        st.success(example["predict"])

        st.markdown("## âœ… Label (Ground Truth)")
        st.info(example["label"])
    else:
        st.warning("ğŸ“ results/generated_predictions_extracted.json íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
