import streamlit as st
import pandas as pd

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="LLM FullAnswer vs GT (In/Out-of-Model)", layout="wide")
st.title("ğŸ“„ LLM FullAnswer vs Ground Truth")

# =========================
# íŒŒì¼ ê²½ë¡œ
# =========================
INMODEL_CSV  = "GT_with_rag_eval_with_all_models.csv"
OUTMODEL_CSV = "rag_eval_with_all_models_out_of_model.csv"
SUMMARY_CSV  = "llm_summary_metrics.csv"
TRAIN_CSV    = "train_dataset.csv"  # ğŸ‘ˆ NEW ì¶”ê°€

# =========================
# ìœ í‹¸
# =========================
@st.cache_data
def load_csv(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df.columns = df.columns.str.strip()
    return df

REQUIRED = [
    "Folder", "GT_Text", "chatgpt4o_FullAnswer",
    "qwen3_FullAnswer", "claude_FullAnswer", "grok4_FullAnswer",
]

NA_PATTERNS = {"not available", "n/a", "na", "none", ""}

def display_text(value) -> str:
    if value is None:
        return "í˜„ì¬ ìš°ë¦¬ëª¨ë¸ì—ì„œëŠ” í•´ë‹¹ ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ ì•Šì•„"
    s = str(value).strip()
    if s.lower() in NA_PATTERNS:
        return "í˜„ì¬ ìš°ë¦¬ëª¨ë¸ì—ì„œëŠ” í•´ë‹¹ ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ ì•Šì•„"
    return s

def check_required(df: pd.DataFrame, label: str):
    missing = [c for c in REQUIRED if c not in df.columns]
    if missing:
        st.error(f"âŒ {label} CSVì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
        st.stop()

def render_block(label: str, df: pd.DataFrame):
    st.subheader(f"ğŸ—‚ï¸ {label} Rows (ë¯¸ë¦¬ë³´ê¸°)")
    preview = df[["Folder", "GT_Text"]].copy()
    preview["chatgpt4o_preview"] = df["chatgpt4o_FullAnswer"].astype(str).str.slice(0, 80) + "..."
    preview["qwen3_preview"]     = df["qwen3_FullAnswer"].astype(str).str.slice(0, 80) + "..."
    preview["claude_preview"]    = df["claude_FullAnswer"].astype(str).str.slice(0, 80) + "..."
    preview["grok4_preview"]     = df["grok4_FullAnswer"].astype(str).str.slice(0, 80) + "..."
    st.dataframe(preview, use_container_width=True, height=320)

    folders = df["Folder"].dropna().astype(str).drop_duplicates().sort_values().tolist()
    sel = st.selectbox(f"ğŸ” {label} - Folder ì„ íƒ:", folders, index=0, key=f"pick_{label}")

    row = df[df["Folder"].astype(str) == sel].iloc[0]

    st.markdown("---")
    st.markdown(f"### ğŸ“ Folder: `{row['Folder']}`")

    st.markdown("### âœ… Ground Truth")
    st.success(display_text(row["GT_Text"]))

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("#### ğŸ¤– ChatGPT-4o")
        st.info(display_text(row["chatgpt4o_FullAnswer"]))
    with c2:
        st.markdown("#### ğŸ¤– Qwen3")
        st.info(display_text(row["qwen3_FullAnswer"]))

    c3, c4 = st.columns(2)
    with c3:
        st.markdown("#### ğŸ¤– Claude")
        st.info(display_text(row["claude_FullAnswer"]))
    with c4:
        st.markdown("#### ğŸ¤– Grok4")
        st.info(display_text(row["grok4_FullAnswer"]))

# =========================
# ë°ì´í„° ë¡œë“œ & ê²€ì¦
# =========================
in_df      = load_csv(INMODEL_CSV)
out_df     = load_csv(OUTMODEL_CSV)
summary_df = load_csv(SUMMARY_CSV)
train_df   = load_csv(TRAIN_CSV)  # âœ… train_dataset.csv

# ê¸°ì¡´ í‰ê°€ìš© ë°ì´í„°ë§Œ ê²€ì¦
check_required(in_df, "In-Model")
check_required(out_df, "Out-of-Model")

# =========================
# íƒ­ ë Œë”ë§
# =========================
tab1, tab2, tab3, tab4 = st.tabs([
    "âœ… In-Model", "ğŸš« Out-of-Model", "ğŸ“Š Summary Metrics", "ğŸ“ Train Dataset"
])

with tab1:
    render_block("In-Model", in_df)

with tab2:
    render_block("Out-of-Model", out_df)

with tab3:
    st.subheader("ğŸ“Š LLM ì „ì²´ ì„±ëŠ¥ ìš”ì•½")
    st.markdown("ê° LLMë³„ ì„±ëŠ¥ ìš”ì•½ ë©”íŠ¸ë¦­ì„ ë¹„êµí•´ë³´ì„¸ìš”.")

    display_df = summary_df.copy().set_index("Model")
    styled = display_df.style.highlight_max(axis=0, color='red', props="font-weight:bold")
    st.dataframe(styled, use_container_width=True, height=400)

with tab4:
    st.subheader("ğŸ“ Train Dataset Viewer")
    st.markdown("í•™ìŠµìš©ìœ¼ë¡œ ìƒì„±ëœ `train_dataset.csv` íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.")
    st.dataframe(train_df, use_container_width=True, height=600)
